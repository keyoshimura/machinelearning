{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## はじめに\n",
    "\n",
    "\n",
    "適当に\n",
    "\n",
    "\n",
    "\n",
    "## 目次\n",
    "- [1.アダブースティング(Adaptive Boosting)](#sec1)  \n",
    "- [2.特徴](#sec2)  \n",
    "- [3.処理の流れ_概要](#sec3)  \n",
    "- [4.処理の流れ_詳細](#sec4)  \n",
    "- [5.発展 ](#sec5)  \n",
    "- [6.まとめ](#sec6)  \n",
    "- [7.参考文献](#sec7)  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<a name=\"sec1\"></a>\n",
    "## 1.アダブースティング(Adaptive Boosting)\n",
    "\n",
    "アンサンブル学習法の１つ。\n",
    "有名なアンサンブル学習法に「バギング」と「ブースティング」があるが、「ブースティング」の中で特に有名な手法が「アダブースティング」である。\n",
    "有名ゆえに「ブースティング」と言ったら「アダブースティング」を指すことが多い。\n",
    "\n",
    "ざっくり言うと、「アダブースティング」は、**「間違えた箇所をより重点的に学習する」ということを何回か繰り返すことで、弱学習器から強い学習器を作る手法。**\n",
    "前回のモデルによる誤差を利用するので**「並列化はできない」**点に注意が必要。  \n",
    "「Adaptive（適応できる）」というのは**「前回の学習結果を次の学習に反映できる」**くらいの意味だと解釈した。\n",
    "\n",
    "また、回帰・分類のいずれにも適用可能で、弱学習器には「教師あり学習」を利用する。\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<a name=\"sec2\"></a>\n",
    "## 2.特徴\n",
    "1.事前のチューニングが不要<br>\n",
    "2.ノイズの影響を受けやすい（過剰適合しやすい）\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<a name=\"sec3\"></a>\n",
    "## 3.処理の流れ_概要\n",
    "２値分類の場合で説明します。\n",
    "アダブースティングでは「データの重みベクトル」と「弱識別器の重み（T次元）」の２つのベクトルが特徴的ですね。\n",
    "\n",
    "1:\tデータと弱識別器（Z個）を用意する。  \n",
    "2:\tデータの重みベクトルを初期化。（w<sub>1</sub>(x) = 1 / M）  \n",
    "    （データの重みベクトルとは、次の学習でどれだけそのデータを重要視して学習させるか、というベクトルである。）\n",
    "3:\tデータの重みベクトルがw<sub>t</sub>の状態で、Z個の弱識別器で学習を行う。  \n",
    "4:\tもっとも重み付き誤差が小さい各弱識別器(h<sub>t</sub>)を1つだけ選ぶ。  \n",
    "     ここでの「重み付き」とは、データの重みベクトル(w<sub>t</sub>)を元に計算することである。  \n",
    "5:\t上記で選択した弱識別器の重み付き誤差を元に、取り出した弱識別器の重み(α<sub>t</sub>)を更新する。  \n",
    "6:\tデータの重みベクトル(w<sub>t</sub>)を更新。  \n",
    "7:\t3-6を最初に指定した回数分(T回)繰り返す\n",
    "8:\t弱識別器の重み付き和を計算することで、強分類器を構築する。 \n",
    "\n",
    "\n",
    "Z個の弱識別器とあるが、これは１つのアルゴリズムをZ個使ってもよいし、Z種類のアルゴリズムを利用しても良いのかな...?\n",
    "（吉村がよくわかっていない）\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<a name=\"sec4\"></a>\n",
    "## 4.処理の流れ_詳細\n",
    "ちょっとつまづきそうなところだけ説明。\n",
    "\n",
    "\n",
    "#### 4-1.弱識別器ごとの重み付き誤差の計算  \n",
    "各反復回数での識別器の重み付き誤差を**$ε_t$**とした時、下記の計算式で求める。  \n",
    "$\\hat{y}$は弱識別器から予測されるラベル、yは正解のラベルです。\n",
    "\n",
    "\\begin{equation*}\n",
    "ε_t = w_t (\\hat{y} \\neq y)\n",
    "\\end{equation*}\n",
    "\n",
    "#### 4-2.弱識別器の重み(α<sub>t</sub>)  \n",
    "上記で求めた「各反復回数ごとの弱識別器の重み付き誤差(**$ε_t$**)」を利用して計算する。\n",
    "\n",
    "\\begin{equation*}\n",
    " α_t = \\frac{1}{2}\\log \\frac{1-ε_t}{ε_t}\n",
    "\\end{equation*}\n",
    "\n",
    "誤分類率がちょうど50%だった場合はその弱識別器は最終的な識別器を求める段階では無視されるね。  \n",
    "誤分類率が50%以上になると負の値をとる点に注意。  \n",
    "精度が高い弱識別器はより強く優先される。\n",
    "\n",
    "\n",
    "#### 4-3.データの重みベクトル(w<sub>t</sub>)の更新\n",
    "弱識別器(h<sub>t</sub>)が誤分類したデータの重みベクトル(w<sub>t</sub>)を大きくし、正しく分類したデータの重みを小さくする。  \n",
    "(次のステップで誤分類したデータをよりモデルに重点的に反映させるため)  \n",
    "\n",
    "\n",
    "\\begin{equation*}\n",
    " w :=  w * exp(-α_t  * \\hat{y} * y)\n",
    "\\end{equation*}\n",
    "\n",
    "正しく分類したデータについては、$\\hat{y} * y$が正になり、誤分類したデータについては負になる。  \n",
    "なので、次のステップで重みが大きくなるか、小さくなるかは「弱識別器の重みが正か負か」、「誤分類したか正しく分類したか」の２軸から判定している。\n",
    "\n",
    "|  | 弱識別器の重みが正 | 弱識別器の重みが負 |\n",
    "|:-----------|-----------:|:------------:|\n",
    "| 誤分類 | $\\nearrow$ | $\\searrow$ |\n",
    "| 正しく分類 | $\\searrow$ | $\\nearrow$ | \n",
    "\n",
    "ここで注目したい点として、**「アダブースティングでは精度が悪いモデルも有効活用する」**という点である。\n",
    "精度が悪い（２値分類で精度が50%未満）モデルの場合、「弱識別器の重み」が負になる。この時誤分類したものについては「モデルを正しく選択すれば正しく分類できる」とポジティブに捉えているのである。\n",
    "\n",
    "\n",
    "また、このデータの重みベクトルは最終的に正規化して合計が１になるようにする。\n",
    "\n",
    "\\begin{equation*}\n",
    " w := \\frac{w}{\\sum_{t=1}^{T}w}\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "#### 4-4.最終的な強識別器\n",
    "最終的に求められる強学習器では、T個得られた弱学習器(h<sub>t</sub>)とそれらの重み(α<sub>t</sub>)から下記のような計算をする。\n",
    "\n",
    "\\begin{equation*}\n",
    "H(x) = sign(\\sum_{t=1}^{T} α_t * h_t(x))\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "この数式の意味は、各弱識別器の予測結果に重みをかけた結果の平均が0より大きければ正例、小さければ負例とする.といった意味である。\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<a name=\"sec5\"></a>\n",
    "## 5.発展  \n",
    "アダブースティングから発展したアルゴリズムについて。\n",
    "\n",
    "#### 5-1.勾配ブースティング  \n",
    "勾配降下法を使ったブースティング\n",
    "\n",
    "\n",
    "#### 5-2.GBDT  \n",
    "弱学習器に決定木を使った勾配ブースティング\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<a name=\"sec6\"></a>\n",
    "## 6.まとめ\n",
    "アダブースティングについて勉強したが、今回は２値分類のみに焦点を絞っていた。  \n",
    "これを多クラス分類や回帰に使うとどのようになるかを勉強しよう。  \n",
    "また、発展したアルゴリズムについてもまとめたい。\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "<a name=\"sec7\"></a>\n",
    "## 7.参考文献\n",
    "- [Python機械学習プログラミング 達人データサイエンティストによる理論と実践](https://www.amazon.co.jp/Python%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%9F%E3%83%B3%E3%82%B0-%E9%81%94%E4%BA%BA%E3%83%87%E3%83%BC%E3%82%BF%E3%82%B5%E3%82%A4%E3%82%A8%E3%83%B3%E3%83%86%E3%82%A3%E3%82%B9%E3%83%88%E3%81%AB%E3%82%88%E3%82%8B%E7%90%86%E8%AB%96%E3%81%A8%E5%AE%9F%E8%B7%B5-impress-top-gear%E3%82%B7%E3%83%AA%E3%83%BC%E3%82%BA-ebook/dp/B01HGIPIAK/ref=sr_1_1?s=digital-text&ie=UTF8&qid=1514115340&sr=1-1&keywords=Python%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%9F%E3%83%B3%E3%82%B0+%E9%81%94%E4%BA%BA%E3%83%87%E3%83%BC%E3%82%BF%E3%82%B5%E3%82%A4%E3%82%A8%E3%83%B3%E3%83%86%E3%82%A3%E3%82%B9%E3%83%88%E3%81%AB%E3%82%88%E3%82%8B%E7%90%86%E8%AB%96%E3%81%A8%E5%AE%9F%E8%B7%B5)\n",
    "- [アンサンブル法による機械学習：基礎とアルゴリズム](https://www.amazon.co.jp/dp/B073F12L1V/ref=dp-kindle-redirect?_encoding=UTF8&btkr=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

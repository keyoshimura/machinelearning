{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 最初に\n",
    "\n",
    "### 本エントリーについて\n",
    "・本エントリーは、「YOLOの論文紹介」になります。そのため、「実際にやってみた」といった内容を含みません。  \n",
    "・本エントリー執筆時点で、YOLOはv3まで出ていますが、その原点となる最初の「YOLO」についての紹介です。\n",
    "\n",
    "### YOLOについて\n",
    "画像認識のアルゴリズムで、2016年に発表された。  \n",
    "リアルタイムで処理かつ高精度で処理できる。  \n",
    "また、１つのCNNネットワークで処理を完結しているため、学習が比較的容易。  \n",
    "コードの商用利用不可。  \n",
    "[論文はこちら](https://arxiv.org/pdf/1506.02640.pdf)\n",
    "\n",
    "# 目次\n",
    "1.introduction  \n",
    "2.Unified Detection  \n",
    "3.Comparison to Other Detection Systems  \n",
    "4.Experiments  \n",
    "5.Real-Time Detection In The Wild  \n",
    "6.Conclusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.introduction(序論)\n",
    "既存の画像認識のアルゴリズムである「DPM」や「R-CNN系」は、画像の領域推定と分類が分断されており、それゆえ処理が複雑であり、かつ処理時間も長くなりがちであった。\n",
    "「YOLO」では、画像認識を回帰問題に落とし込むことで「画像の領域推定」と「分類」を同時に行うことを実現した。\n",
    "「YOLO」のアルゴリズムは１つのCNNで完結するためシンプルであり、また既存の手法と比較して下記のようなメリットを得ることができる。\n",
    "\n",
    "##### メリット1.処理が早い\n",
    "シンプルな回帰問題に落とし込んだことで、「複雑なパイプラインを考慮する必要がなくなった」ため処理が早い。\n",
    "「通常のYOLO」（Titan X GPUを利用）の検証では45f/sec、「より早いバージョン」での検証では150f/secを発揮した。\n",
    "これはリアルタイムのストリーミングビデオを25msec程度のレイテンシーで処理できるパフォーマンスである。\n",
    "また、既存のリアルタイム処理アルゴリズムと比較して倍以上の精度（mAP）を発揮した\n",
    "\n",
    "##### メリット2.画像全体を見て予測することができる\n",
    "既存のアルゴリズムでは「sliding window」や「」等の手法を使って、物体の候補領域を検出しようとしていた。  \n",
    "この手法のせいか、例えば「Fast R-CNN」は背景を物体だと誤検出することが多かった。  \n",
    "「YOLO」では、画像全体の情報から学習や検証を実施することができるので、上記のような誤検出が「Fast R-CNN」の半分以下となっている。\n",
    "\n",
    "##### メリット3.\n",
    "YOLOは汎化性能が高い\n",
    "\n",
    "\n",
    "最先端なアルゴリズムと比較すると、YOLOはまだ精度の面で劣っている。\n",
    "この後の検証で確認するが、YOLOは処理速度は早い一方で「小さいもの」の検出が弱点なのである。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Unified Detection\n",
    "\n",
    "##### 概要\n",
    "YOLOでは、画像をS×Sのgridに分割する。  \n",
    "各「grid　cell」はB個の「bounding boxes(物体の候補領域)」と、各「bounding boxの信頼度」を計算する。  \n",
    "各「bounding box」は下記の5つのパラメータからなる。  \n",
    "\n",
    "x:「bounding box」の中心の座標（x軸）  \n",
    "y:「bounding box」の中心の座標（y軸）  \n",
    "w:「bounding box」の横幅  \n",
    "h:「bounding box」の高さ  \n",
    "信頼度:上述の通り  \n",
    "\n",
    "\n",
    "また、各「grid cell」は下記のような条件付き確率をもつ。\n",
    "\n",
    "```math\n",
    "p(その物体が何であるか | そのgrid cellに物体がある確率)\n",
    "```\n",
    "\n",
    "今回は、「PASCAL VOC」のデータセットを利用して検証を進めた。\n",
    "また、本検証でのパラメータは下記の通り。\n",
    "\n",
    "S:7\n",
    "B:2\n",
    "物体のクラス数:20(データセットが２０種類の物体からなるデータセットなので)\n",
    "\n",
    "\n",
    "##### ネットワーク構造\n",
    "序論で述べたとおり、「YOLO」は単一のCNNネットワーク構造からなる。\n",
    "下記の画像を参照いただくとイメージがつきやすいかと思うが、最初のconv層(24層)で特徴量を抽出し、最後の全結合層(2層)で「分類」や「物体領域の座標修正」を行う。\n",
    "# ここに画像を入れる\n",
    "\n",
    "また、本論文では上記のとは別に「Fast YOLO」についても検証を進めた。\n",
    "こちらは畳み込み層が9層になり、フィルターも少なくした以外はYOLOと同じもの。計算量が減るため処理が早い。\n",
    "\n",
    "\n",
    "##### 学習\n",
    "まず最初の20層の畳み込み層で事前学習をした。\n",
    "この時点で、「ImageNet1000-class competition dataset」の「top-5 accuracy」で88%の結果だった。\n",
    "この事前学習の後に、4層の畳み込み層と２層の全結合層を追加する形で本モデルを生成した。（初期パラメータは、乱数で適当に設定）\n",
    "（このような、事前学習したモデルに後から畳み込み層と結合層を追加するやり方はパフォーマンスを上げてくれる、らしい。）\n",
    "[詳細はこちら](https://arxiv.org/pdf/1504.06066.pdf)\n",
    "\n",
    "\n",
    "##### 正規化\n",
    "「bounding box」の座標、横幅、高さについて０から１の範囲に収まるように正規化をした。\n",
    "\n",
    "##### optimizer\n",
    "\n",
    "最後の結合層では線形の活性化関数を利用した。\n",
    "それ以外の層では下記の活性化関数を利用した。\n",
    "\n",
    "```math\n",
    "φ(x) = x, if x > 0\n",
    "            0.1x, otherwise\n",
    "```\n",
    "\n",
    "##### cost関数\n",
    "簡単で使いやすいから二乗和誤差を使ったが、これは「理想ではない」と論文中では言っている。\n",
    "（「分類誤差」と「候補領域抽出誤差」を同等に扱ってしまう、ほとんどのcellが物体を含まないために勾配消失が起きてしまい学習をやたらと早く収束させてしまう）\n",
    "\n",
    "この問題に対応するために、下記の２つのパラメータを導入した。\n",
    "・物体がない場合はあまり学習に反映させない\n",
    "・物体があった場合の分類ミスは大きく反映させる\n",
    "\n",
    "また、二乗和誤差だとバウンディングボックス（BB）が大きくても小さくても誤差は同じものとして計算してしまう。\n",
    "本アルゴリズムとしては、大きなBBには小さなBBよりも小さな誤差としてほしいので、BBのw,hはそのままの値ではなく平方根を利用した。\n",
    "\n",
    "\n",
    "##### トレーニング中に最適化した関数について\n",
    "\n",
    "長すぎるのでここでは数式は書かないが、概要だけ記述する。  \n",
    "・「分類誤差のペナルティ」は「grid cellに物体が存在する場合」のみ設ける  \n",
    "・「BBの座標誤差のペナルティ」は「各grid cellでもっともIoUが高い場合」のみ設ける\n",
    "\n",
    "下記の関数が小さくなるように学習を進めた。  \n",
    "\n",
    "```math\n",
    "(最適化する関数) =\n",
    "                            (BBに物体があった場合の、x,y座標の誤差) + \n",
    "                            (BBに物体があった場合の、横幅と高さの誤差) + \n",
    "                            (BBに物体があった場合の、BBの信頼度誤差) + \n",
    "                            (BBに物体が無かった場合の、BBの信頼度誤差) + \n",
    "                            (BBに物体があった場合の、分類誤差) \n",
    "```\n",
    "\n",
    "##### トレーニング中のあれこれ\n",
    "学習係数\n",
    "最初は小さく設定する。そうでないと勾配が安定しない。\n",
    "最初の７５エポックは10^-2,次の３０は10^-3,最後の30は10^-4とした。\n",
    "\n",
    "エポック数:135  \n",
    "バッチサイズ:64  \n",
    "モーメンタム:0.9  \n",
    "decay:0.0005  \n",
    "\n",
    "過学習の回避のために、「dropout」と「データ拡張」を行った。  \n",
    "「dropout」は最初の結合層のところで、半分のノードをドロップアウトする。  \n",
    "「データ拡張」は元データの２０%くらいを新しく生成した。\n",
    "\n",
    "\n",
    "##### non-maximal suppression\n",
    "YOLOでは、１つの物体が複数のcellから抽出されてしまうことがある。  \n",
    "（大きな物体やちょうどcellの分割点に存在する物体等）  \n",
    "そのような物体を「１つの物体」として認識するために「non-maximal suppression」を利用した。  \n",
    "\n",
    "\n",
    "##### YOLOの制限\n",
    "１つのgridで分類できる物質はパラメータとして設定した「BB数」に制限されてしまう。  \n",
    "また、各BBにおける予測クラスは１つのみになってしまう。\n",
    "そのため「小さな物体の集まり」（ex.鳥の大群）の識別が苦手。\n",
    "\n",
    "また、「既存とは異なるアスペクト比を持つ物体」の検出も苦手。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./work/YOLO/network.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.既存手法との比較\n",
    "\n",
    "### 3-1.DPM(Deformable parts models)\n",
    "YOLOでは、１つのネットワークで完結する点が異なる。  \n",
    "１つのネットワークで全てを完結させることで、最終的なパフォーマンス、精度の向上に繋がる。\n",
    "\n",
    "### 3-2.R-CNN\n",
    "R-CNNやその派生系も、特徴量抽出やBB検出、物体分類等で異なるモジュールを使うのでチューニングが大変かつ、処理が遅い。  \n",
    "また、YOLOはその制約により、一つのgridに識別するBBの数を制限しているので、「同じ物体を重複して出力する」というR-CNNのデメリットを和らげている。  \n",
    "\n",
    "「Fast R-CNN」、「Faster R-CNN」でも、「リアルタイム処理」を謳うためには処理が遅い。\n",
    "\n",
    "\n",
    "### 3-3.Deep MultiBox\n",
    "「ある特定の物質を検知する」目的には利用できるかもしれないが、あくまでも物体検出をおこなう上でのパーツの１つに過ぎない。  \n",
    "YOLOは物体検出において「より汎化的な」アルゴリズムであるとのこと。  \n",
    "BBを推測する際にCNNで特徴量を抽出するところは共通点ではある。\n",
    "\n",
    "### 3-4.OverFeat\n",
    "物体検出と分類を同時にできるものではない。\n",
    "\n",
    "### 3-5.MultiGrasp\n",
    "思想は似ている。ただ、MultiGraspは処理できる内容が単純すぎる。  \n",
    "（物体のサイズや他クラス分類ができない等）  \n",
    "その点、YOLOは１つの画像で複数の物体＆複数のクラスへの分類が可能である。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.検証\n",
    "YOLOとR-CNNの派生系の中で一般的な「Fast R-CNN」の処理結果を比較する。  \n",
    "\n",
    "### 4-1.リアルタイムで処理できるシステムとの比較  \n",
    "「リアルタイムで」処理できると思われる手法は[Sadeghi et al」が提案した手法](M. A. Sadeghi and D. Forsyth. 30hz object detection with dpm v5. In Computer Vision–ECCV 2014, pages 65–79.Springer, 2014. 5, 6)で、この手法だと30fpsというパフォーマンスが証明されている。  \n",
    "なので、YOLOと上記手法を比較した。他の手法は処理速度と精度の観点から比較するレベルに至っていないためである。  \n",
    "「Fast YOLO」が一番処理が早いものの、精度(mAP)が52.7%であった。（既存のリアルタイム検出手法の２倍以上の精度）  \n",
    "一方、YOLOはリアルタイムで処理できるパフォーマンスを維持しつつもmAPを63.4％にまで押し上げた。  \n",
    "VGG-16を使ったYOLOも試したが、精度は向上したもののリアルタイム処理ができるほどのパフォーマンスが得られなかった。  \n",
    "「Fastest DPM」は、処理速度がまだリアルタイム処理できるほどのものではないうえに精度がそこまで高くない。  \n",
    "「R-CNN Minus R」はリアルタイム処理するとは程遠い。\n",
    "「Fast R-CNN」はmAPは高いが、リアルタイム処理とは程遠い。  \n",
    "「Faster R-CNN」も同様に、まだリアルタイム処理とは程遠い。\n",
    "\n",
    "\n",
    "##### リアルタイム処理ができると思われる手法\n",
    "\n",
    "| 手法 | トレーニングデータ | mAP | FPS |\n",
    "|---|---|---|\n",
    "|100Hz DPM | 2007 | 16.0 | 100 |\n",
    "|30Hz DPM | 2007 | 26.1 | 30 |\n",
    "|Fast YOLO | 2007+2012 | 52.7 | 155 |\n",
    "|YOLO | 2007+2012 | 63.4 | 45 |\n",
    "\n",
    "\n",
    "##### リアルタイム処理はできなさそうな手法\n",
    "| 手法 | トレーニングデータ | mAP | FPS |\n",
    "|---|---|---|\n",
    "|Fastest DPM | 2007 | 30.4 | 15 |\n",
    "|R-CNN Minus R | 2007 | 53.5 | 6 |\n",
    "|Fast R-CNN | 2007+2012 | 70.0 | 0.5 |\n",
    "|Faster R-CNN VGG-16 | 2007+2012 | 73.2 | 7 |\n",
    "|Faster R-CNN ZF | 2007+2012 | 62.1 | 18 |\n",
    "|YOLO VGG-16 | 2007+2012 | 66.4 | 21 |\n",
    "\n",
    "\n",
    "### 4-2.VOC 2007 Error Analysis\n",
    "最先端の手法（Fast R-CNN）とYOLOの違いをより明確にするために、「誤差の内容」を調査しました。\n",
    "評価指標は[ Hoiem et al.](D. Hoiem, Y. Chodpathumwan, and Q. Dai. Diagnosing error in object detectors. In Computer Vision–ECCV 2012, pages\n",
    "340–353. Springer, 2012. 6)を参考にした。  \n",
    "\n",
    "「YOLO」は「Fast R-CNN」と比較すると「背景を物体と誤認識しない」点について高いパフォーマンスを発揮していた。  \n",
    "\n",
    "\n",
    "\n",
    "### 4-3.Fast R-CNNとYOLOを組み合わせてみた  \n",
    "\n",
    "YOLOは「背景を物体と認識しない」点について精度が高いので、そのメリットを活かす形で「Fast R-CNN」と組み合わせたところ、「Fast R-CNN」の精度（mAP）がちょっとだけ向上した。  \n",
    "具体的には、「Fast R-CNN」が出力したBBをYOLOもBBとして出力しているか、というチェックを加えるイメージで組み合わせた。  \n",
    "\n",
    "結局２つのモデルを処理させることになるので処理時間に問題があるのだが、YOLOの処理時間が短いので大きな問題にはならない。  \n",
    "既に、「Fast R-CNN」を使っている場合には、この組み合わせを利用することで精度向上を図ることができる。  \n",
    "\n",
    "\n",
    "### 4-4.VOC 2012 Results\n",
    "VOC 2012のデータセットでも検証した。  \n",
    "YOLOのmAPは57.9%で、他の最先端の手法よりも低かった。  \n",
    "クラスごとに分類結果を見てみると、「ボトル」や「羊」等の小さい物質の検出にミスが多いようだった。  \n",
    "逆に「猫」や「電車」等のクラスの分類はよくできていた。  \n",
    "「Fast R-CNN」と「YOLO」を組み合わせたモデルは、トップクラスのパフォーマンスを発揮した。  \n",
    "\n",
    "\n",
    "### 4-5.美術作品中の人物分類\n",
    "アカデミックな世界では学習用と検証用データが「同じところから」派生するが、実社会においてはそうとはならず、学習に利用したものとは全く異なる分類をしなくてはならないため実用が難しい。  \n",
    "そこで、汎用性を確認する一環として「ピカソや人物画から人間を適切に抽出できるか」、という検証を実施した。\n",
    "結果は下記の通りだった。\n",
    "\n",
    "| 手法 | VOC 2007　AP | Picasso AP| Picasso　Best F1 | People-Art　AP |\n",
    "|---|---|---|---|\n",
    "|YOLO | 59.2 | 53.3 | 0.590 | 45 |\n",
    "|R-CNN | 54.2 | 10.4 | 0.226 | 26 |\n",
    "|DPM | 43.2 | 37.8 | 0.458 | 32 |\n",
    "|Poselets | 36.5 | 17.8 | 0.271 | 　 |\n",
    "|D&T |   | 1.9 | 0.051 |   |\n",
    "\n",
    "\n",
    "以上から、下記の通り整理できる。\n",
    "・R-CNN\n",
    "VOC2007については高いAPを維持できるものの、美術作品に対しては精度が低い。\n",
    "「R-CNN」は「selective search」を採用しているが、このアルゴリズムは通常の画像に対して利用するのがいいであろう。\n",
    "\n",
    "・DPM\n",
    "「DPM」は美術作品に対しても精度をある程度維持できている。\n",
    "ただ、元々の精度が良くない。\n",
    "\n",
    "・YOLO\n",
    "「VOC 2007」、美術作品のいずれにおいてももっとも高い精度を発揮した。\n",
    "これは「YOLO」では物体のサイズ、形、周囲との関係性までモデリングできているからであろう。\n",
    "美術作品と通常の画像では「ピクセルレベル」で見ると全く異なるが、「物体のサイズや形」といった面では似ているので「YOLO」はこのようなパフォーマンスを発揮できたのだろう。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.Real-Time Detection In The Wild\n",
    "YOLOをWebカメラに接続して、リアルタイムでのパフォーマンスを実世界で検証してみた。\n",
    "結果は[こちら](http://pjreddie.com/yolo/.)をご参照ください。\n",
    "\n",
    "\n",
    "# 6.Conclusion\n",
    "「YOLO」は単一のネットワークで完結している点が従来の手法と異なる。\n",
    "「Fast YOLO」は汎用的な物体検出としてはもっとも早いアルゴリズムであり、「YOLO」はリアルタイム画像認識の最先端の手法と言えるだろう。（2016年５月時点）\n",
    "また、「YOLO」は新しいドメインの画像にも対応できるのでアプリケーションへの適用に適しているだろう。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 備考\n",
    "\n",
    "##### IoU(Intersection over Union)\n",
    "[このブログ](https://meideru.com/archives/3538)の解説がとてもわかりやすくて良い。  \n",
    "\n",
    "\n",
    "##### Non-Maximum Suppression\n",
    "\n",
    "論文中でもさらっと出てきているが、これはなんなのか。  \n",
    "[このブログ](https://meideru.com/archives/3538)の解説がとてもわかりやすくて良い。  \n",
    "同じクラスと予測したBBが重複している際、一つの領域として調整するアルゴリズムのようです。\n",
    "\n",
    "IoU値が閾値よりも大きい場合は、その領域を抑制（suppression）する、というもの。\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python35",
   "language": "python",
   "name": "python35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
